{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91044bcc",
   "metadata": {},
   "source": [
    "# ModelEDA class\n",
    "This class is used to explore model predictions and scores after creating and optimizing models using `MyModel` class. (See class documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d36c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import os\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4db6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilmott_index(y_measured, y_hat, c = 2):\n",
    "    '''\n",
    "    Compute the refined wilmott index\n",
    "    '''\n",
    "    y_avg = y_measured.mean()\n",
    "    \n",
    "    # part1 = sum( | predictions - measurements| )\n",
    "    part1 = np.sum(np.abs(y_hat - y_measured))\n",
    "    \n",
    "    # part2 = c * sum( |measurements - meas_avg| )\n",
    "    part2 = c * np.sum(np.abs(y_measured - y_avg))\n",
    "    \n",
    "    if part1 <= part2:\n",
    "        return 1 - part1/part2\n",
    "    \n",
    "    else:\n",
    "        return part2/part1 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38686aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEDA:\n",
    "    \n",
    "    '''\n",
    "    This class is used to explore model predictions and scores after creating and optimizing models using MyModel class.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    model_name: str\n",
    "        Model name as used in MyModel\n",
    "        \n",
    "    algorithm: str\n",
    "        Name of the algorithm used. The directory which has the models saved in should\n",
    "        have the same name as `algorithm`.\n",
    "        \n",
    "    model_type: str\n",
    "        If different sub-categories of the algorithms were used to create the models, this\n",
    "        should be the name of the sub-category of the algorithm. Default is an empty string (No sub-category).\n",
    "        Note that the models, predictions, etc. should be stored ina directory that has the same name as `model_type`\n",
    "        and found inside a directory that has the same name as `algorithm`.\n",
    "        \n",
    "    save_path: str\n",
    "        Path to the directory containing the algorithm/model_type directories.\n",
    "        \n",
    "    data_path: str\n",
    "        Path to the directory containing the processed data. This directory should contain the files train.csv, test.csv,\n",
    "        and station_definitions.csv.\n",
    "        \n",
    "    score_fun_dict: dict\n",
    "        A dictionary of metric functions to be used for evaluating the model\n",
    "        \n",
    "    \n",
    "    Methods:\n",
    "    --------\n",
    "    \n",
    "    get_model():\n",
    "        Return the MyModel object of the defined feature_combo\n",
    "        \n",
    "    get_predictions():\n",
    "        Return the train or test predictions of the defined feature_combo\n",
    "        \n",
    "    get_train_test():\n",
    "        Get the measurements of the train or test dataset.\n",
    "        Returns a dataframe containing the columns: ['st_num', 'date', 'ET0']\n",
    "        \n",
    "    get_station_scores():\n",
    "        Returns the scores per station.\n",
    "        \n",
    "    get_scores():\n",
    "        Returns a dataframe containing the scores of the model.\n",
    "        \n",
    "    get_feature_table():\n",
    "        Returns a table of features from the defined feature_combos.json file.\n",
    "        \n",
    "    compare_combinations():\n",
    "        Returns a dataframe containing the scores of all feature combinations of the test or train dataset\n",
    "    \n",
    "    plot_combo_scores():\n",
    "        Plot a bar plot comparing the scores of all feature combinations.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    \n",
    "    def __init__(self,\n",
    "                 model_name,\n",
    "                 algorithm,\n",
    "                 model_type='',\n",
    "                 save_path = r\"C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\part_3\",\n",
    "                 data_path = r'C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\processed_data',\n",
    "                 score_fun_dict = {\n",
    "                       'MAE': mean_absolute_error,\n",
    "                       'RMSE': lambda x, y: np.sqrt(mean_squared_error(x, y)),\n",
    "                       'R2': r2_score,\n",
    "                       'WI': wilmott_index\n",
    "                   }\n",
    "                ):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.save_path = os.path.join(save_path, algorithm, model_type)\n",
    "        self.data_path = os.path.join(data_path)\n",
    "        self.score_fun_dict = score_fun_dict\n",
    "        self.algorithm = algorithm\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_model(self, feature_combo):\n",
    "        \n",
    "        '''\n",
    "        Return the MyModel object of the defined feature_combo\n",
    "        '''\n",
    "        model_name = self.model_name + '_' + str(feature_combo)\n",
    "       \n",
    "        m = MyModel(model_name = model_name,\n",
    "                    save_path = self.save_path,\n",
    "                    data_path = self.data_path\n",
    "                   )\n",
    "        \n",
    "        return m\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_predictions(self, feature_combo, train_test = 'test'):\n",
    "        '''\n",
    "        \n",
    "        Return the train or test predictions of the defined feature_combo\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        feature_combo: int\n",
    "        \n",
    "        train_test: str\n",
    "            Determines whether to return train or test predictions\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        assert train_test in ['train', 'test'], '\"train_test\" must be \"train\" or \"test\"'\n",
    "        \n",
    "        model_name = self.model_name + '_' + str(feature_combo)\n",
    "        file_name = model_name + '_pred.npz'\n",
    "        file_path = os.path.join(self.save_path, file_name)\n",
    "        preds = np.load(file_path)\n",
    "        \n",
    "        name = 'y_hat_' + train_test\n",
    "        y_hat = preds[name]\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_train_test(self, train_test='test'):\n",
    "        \n",
    "        '''\n",
    "        Get the measurements of the train or test dataset.\n",
    "        Returns a dataframe containing the columns: ['st_num', 'date', 'ET0']\n",
    "        '''\n",
    "        \n",
    "        assert train_test in ['train', 'test'], 'which must be \"train\" or \"test\"'\n",
    "        \n",
    "        file_name = train_test + '.csv'\n",
    "        file_path = os.path.join(self.data_path, file_name)\n",
    "        df = pd.read_csv(file_path, parse_dates = [2])[['st_num', 'date', 'ET0']]\n",
    "        \n",
    "        return df\n",
    "      \n",
    "        \n",
    "    \n",
    "    def get_station_scores(self, feature_combo):\n",
    "        '''\n",
    "        Returns the scores per station\n",
    "        '''\n",
    "        \n",
    "        model_name = self.model_name + '_' + str(feature_combo)\n",
    "        file_name = 'station_scores.csv'\n",
    "        file_path = os.path.join(self.save_path, file_name)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Slicing the part with the desired model name and feature combination\n",
    "        cond1 = df['name'] == model_name\n",
    "        cond2 = df['feature_combo'] == feature_combo\n",
    "        \n",
    "        df = df.loc[cond1 & cond2].reset_index(drop=True)\n",
    "        \n",
    "        return df \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_scores(self):\n",
    "        \n",
    "        '''\n",
    "        Returns a dataframe containing the scores of the model\n",
    "        '''\n",
    "        \n",
    "        file_name = 'scores.csv'\n",
    "        file_path = os.path.join(self.save_path, file_name)\n",
    "    \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        cond = df['algorithm'] == self.algorithm\n",
    "        \n",
    "        return df.loc[cond].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_feature_table(self,\n",
    "                          path=r\"C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\part_3\\feature_combos.json\",\n",
    "                          long=True):\n",
    "        \n",
    "        '''\n",
    "        Returns a table of features from the defined feature_combos.json file\n",
    "        '''\n",
    "        \n",
    "        with open(path, 'r') as f:\n",
    "            features = json.load(f)\n",
    "            \n",
    "        feature_dict =  {'latitude': 'Latitude',\n",
    "                         'longitude': 'Longitude',\n",
    "                         'elevation': 'Elevation',\n",
    "                         'max_temp': 'Maximum temperature',\n",
    "                         'min_temp': 'Minimum temperature',\n",
    "                         'avg_temp': 'Average Temperature',\n",
    "                         'avg_ws': 'Average wind speed',\n",
    "                         'max_hum': 'Maximum humidity',\n",
    "                         'min_hum': 'Minimum humidity',\n",
    "                         'avg_hum': 'Average humidity',\n",
    "                         'Rs': 'Solar radiation',\n",
    "                         'inc_rad': 'Solar radiation',\n",
    "                         'Ra': 'Extraterrestrial radiation',\n",
    "                         'Rn': 'Net radiation',\n",
    "                         'ET0': 'Reference evapotranspiration',\n",
    "                         'month': 'Month'}\n",
    "        \n",
    "        if long==True:\n",
    "            fun = lambda x: ', '.join([feature_dict[name] for name in x])\n",
    "            vals = list(map(fun, features.values()))\n",
    "            \n",
    "        else:\n",
    "            fun = lambda x: ', '.join(x)\n",
    "            vals = list(map(fun, features.values()))\n",
    "            \n",
    "        features = dict(zip(features.keys(), vals))\n",
    "        \n",
    "        features = pd.DataFrame(features, index = [0]).transpose()\n",
    "        features = features.set_index(np.arange(1, features.shape[0] + 1))\n",
    "        features.index.name = 'Combo'\n",
    "        features = features.rename(columns = {0: 'Features'})\n",
    "        \n",
    "        display(features.style.set_properties(subset=['Features'], **{'width': '500px'}))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "            \n",
    "    \n",
    "    def compare_combinations(self,\n",
    "                             train_test='test'):\n",
    "        '''\n",
    "        Returns a dataframe containing the scores of all feature combinations of the test or train dataset\n",
    "        '''\n",
    "        path = self.save_path\n",
    "        scores = self.get_scores()\n",
    "        \n",
    "        cond = scores['train_test'] == train_test\n",
    "        scores = scores[cond].reset_index(drop=True).sort_values(by='feature_combo')\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "        \n",
    "    def plot_combo_scores(self,\n",
    "                          ax,\n",
    "                          title=None,\n",
    "                          metric = 'RMSE'):\n",
    "        \n",
    "        '''\n",
    "        Plot a bar plot comparing the scores of all feature combinations.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        ax: matplotlib.axes\n",
    "        \n",
    "        title: str\n",
    "        \n",
    "        metric: str\n",
    "            Name of metric to be used. The metric should be defined in the score_fun_dict\n",
    "        '''\n",
    "        \n",
    "        train = self.compare_combinations(train_test = 'train')\n",
    "        train = train[metric]\n",
    "        \n",
    "        test = self.compare_combinations(train_test = 'test')\n",
    "        test = test[metric]\n",
    "        \n",
    "        bar_width = 0.2\n",
    "        bar_offset = bar_width*0.5\n",
    "        \n",
    "        # Bar coordinates\n",
    "        x = train.shape[0] # Number of bar groups to plot\n",
    "        x = np.linspace(1, 10, x)\n",
    "        \n",
    "        # Bar offset from x coordinates\n",
    "        diff = np.zeros(x.shape) + bar_offset\n",
    "        \n",
    "        x1 = x - diff\n",
    "        ax.bar(x = x1, height=train.values, label = 'Train',\n",
    "               color = 'skyblue', width = bar_width)\n",
    "        \n",
    "        x1 = x + diff\n",
    "        ax.bar(x=x1, height=test.values, label='Test',\n",
    "               color='navy', width=bar_width)\n",
    "        \n",
    "        # Annotation\n",
    "        ax.set_xlabel('Combination')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_xticks(x)\n",
    "        xticklabels = list(map(str, range(1, len(x)+1)))\n",
    "        ax.set_xticklabels(xticklabels)\n",
    "        if title is None:\n",
    "            title = '{} per combination'.format(metric)\n",
    "        ax.set_title(title)\n",
    "        \n",
    "        ax.legend(ncol = 2)\n",
    "        ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f378ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
