{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import folium\n",
    "import os\n",
    "import json\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_grid_results(cv_results, param_list = ['C', 'gamma'], drop_split_scores = False):\n",
    "    \"\"\"\n",
    "    Create a readable dataframe from grid search results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    cv_results: Scikit-Learn GridSearchCV.cv_results_ attribute\n",
    "    \n",
    "    param_list: List of parameters optimized with grid search\n",
    "    \n",
    "    drop_split_scores: Boolean to decide whether to drop split scores or not\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(cv_results)\n",
    "    \n",
    "    # Dropping split scores\n",
    "    if drop_split_scores is True:\n",
    "        cond = df.columns.str.contains('split')\n",
    "        cols_to_drop = df.columns[cond]\n",
    "        df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    # Dropping params column\n",
    "    df = df.drop(columns = ['params'])\n",
    "    \n",
    "    cols_to_rename = []\n",
    "    for param in param_list:\n",
    "        cond = df.columns.str.contains(param)\n",
    "        cols_to_rename.append(df.columns[cond][0])\n",
    "    \n",
    "    df = df.rename(columns = dict(zip(cols_to_rename, param_list)))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def text_block(ax, x_start, y_start, main_text, text_list,\n",
    "               main_line_spacing = -0.05, sub_line_spacing = -0.04, indentation = 0.1, fontsize = 12):\n",
    "    \n",
    "    \"\"\"\n",
    "    Write a text block inside an axes object:\n",
    "    Example of a text block:\n",
    "    \n",
    "    Features:\n",
    "        F1\n",
    "        F2\n",
    "    main_text = 'Features:'\n",
    "    text_list = ['F1', 'F2']\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initiating coordinates\n",
    "    y_txt = y_start + main_line_spacing\n",
    "    x_txt = x_start\n",
    "    \n",
    "    # Writing main text\n",
    "    ax.text(x_txt, y_txt, main_text, fontsize = fontsize)\n",
    "    \n",
    "    # Updating coordinates\n",
    "    y_txt += main_line_spacing\n",
    "    x_txt += indentation\n",
    "    \n",
    "    # Iterating through text_list\n",
    "    for txt in text_list:\n",
    "        ax.text(x_txt, y_txt, txt, fontsize = fontsize)\n",
    "        y_txt += sub_line_spacing\n",
    "    \n",
    "    # Resetting x to x_start\n",
    "    x_txt = x_start\n",
    "    \n",
    "    return (x_txt, y_txt)\n",
    "\n",
    "\n",
    "def wilmott_index(y_measured, y_hat, c = 2):\n",
    "    '''\n",
    "    Compute the refined wilmott index\n",
    "    '''\n",
    "    y_avg = y_measured.mean()\n",
    "    \n",
    "    # part1 = sum( | predictions - measurements| )\n",
    "    part1 = np.sum(np.abs(y_hat - y_measured))\n",
    "    \n",
    "    # part2 = c * sum( |measurements - meas_avg| )\n",
    "    part2 = c * np.sum(np.abs(y_measured - y_avg))\n",
    "    \n",
    "    if part1 <= part2:\n",
    "        return 1 - part1/part2\n",
    "    \n",
    "    else:\n",
    "        return part2/part1 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MyModel` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    '''\n",
    "    This class is used to automate some of the repetitive tasks in model\n",
    "    creation and optimization.\n",
    "    \n",
    "    How to use MyModel class prior to model creation:\n",
    "        1. Define model_name, feature_combo, and cluster_name (if studying several clusters)\n",
    "        2. Create MyModel object\n",
    "        3. Load train and test data using relevant methods\n",
    "        4. Create and optimize model\n",
    "        5. Add the model to MyModel object using m.add_model(model)\n",
    "        6. Run m.get_scores(predict = True) to get model scores/errors and save predictions to attributes\n",
    "        7. Create plots:\n",
    "            * m.plot_predictions(): Plots predictions against measurements\n",
    "            * m.plot_station_series(): Plots a time series of predictions against measurements\n",
    "                                       of a certain station\n",
    "        8. Run m.save_model() to save model and predictions.\n",
    "        9. Run m.save_scores() to save model scores and features in the global CSV file\n",
    "    \n",
    "    How to use MyModel class after saving the model:\n",
    "        1. Define `model_name`, `feature_combo`, and `cluster_name` (if available)\n",
    "        2. Create MyModel object, model will be automatically loaded if found in the relative directory\n",
    "        3. Load train and test data using relevant methods\n",
    "        4. Run m.get_scores(predict = False) to get model scores/errors\n",
    "        5. Create plots\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    feature_combo: int\n",
    "        Number of the feature combination\n",
    "    \n",
    "    model_name: str\n",
    "        Model name\n",
    "        \n",
    "    regressor:\n",
    "        Regressor object\n",
    "        \n",
    "    model_params: dict\n",
    "        Regressor object init parameters\n",
    "        \n",
    "    fit_params: dict\n",
    "        Regressor fit parameters\n",
    "    \n",
    "    target:\n",
    "        Target variable. Default is 'ET0'\n",
    "    \n",
    "    save_path:\n",
    "        Path to the directory where the model and predictions are saved.\n",
    "        Default is '' (model is in the same directory)\n",
    "                \n",
    "    data_path:\n",
    "        Path to the directory where the train and test datasets are saved\n",
    "    \n",
    "    cluster_name:\n",
    "        Name of the cluster if available\n",
    "    \n",
    "    score_fun_dict:\n",
    "        A dictionary of metric functions to be used for evaluating the model\n",
    "    \n",
    "    \n",
    "    Methods:\n",
    "    --------\n",
    "    \n",
    "    m.get_feature_names():\n",
    "        Get the full feature names. Used internally to create the attribute m.feature_names\n",
    "                           \n",
    "    m.get_train_test():\n",
    "        Get training dataset from the defined data_path.\n",
    "        Returns the tuple (train, test)\n",
    "                        \n",
    "    m.get_Xy():\n",
    "        Returns (X_train, X_test, y_train, y_test)\n",
    "        Assigns them to attributes\n",
    "        Assigns dataframes of train/test station numbers with measurement dates to attributes\n",
    "        (m.train_stations, m.test_stations)\n",
    "                \n",
    "    m.add_model():\n",
    "        Assign model to attribute m.model\n",
    "    \n",
    "    m.load_model():\n",
    "        Load model from the defined model_path and assign it to attribute m.model\n",
    "        Also loads predictions from the pred_path and assigns them to attributes\n",
    "                    \n",
    "    m.save_model():\n",
    "        Save model and predictions to the defined model_path\n",
    "    \n",
    "    m.get_scores():\n",
    "        Predict y_train and y_test then compute evaluation metrics.\n",
    "        Predictions and metrics are assigned to attributes\n",
    "        \n",
    "    m.get_station_scores():\n",
    "        Get scores per weather station.\n",
    "                    \n",
    "    m.plot_predictions():\n",
    "        Plots predictions against measurements\n",
    "    \n",
    "    m.plot_station_series():\n",
    "        Plots a time series of predictions against measurements of a certain station\n",
    "                             \n",
    "    m.save_scores():\n",
    "        Save model evaluation metrics to a CSV file. This CSV file\n",
    "        contains the scores of all models of the same algorithm.\n",
    "                     \n",
    "    Attributes:\n",
    "    -----------\n",
    "    \n",
    "    m.model_name\n",
    "    \n",
    "    m.feature_dict:\n",
    "        Internally defined dictionary of feature column names vs extended names\n",
    "    \n",
    "    m.features:\n",
    "        List of feature column names used in the model\n",
    "    \n",
    "    m.feature_names:\n",
    "        List of extended feature names used in the model\n",
    "    \n",
    "    m.train_path:\n",
    "        Path to training dataset\n",
    "    \n",
    "    m.test_path\n",
    "        Path to test dataset\n",
    "        \n",
    "    m.regressor\n",
    "        Regressor object\n",
    "        \n",
    "    m.model_params\n",
    "        Regressor object init parameters\n",
    "        \n",
    "    m.fit_params\n",
    "        Regressor fit parameters\n",
    "    \n",
    "    m.target:\n",
    "        Name of target variable\n",
    "    \n",
    "    m.save_path:\n",
    "        Path to the directory to save the model, predictions, parameters, and scores to.\n",
    "        \n",
    "    m.model_path:\n",
    "        Path to model file\n",
    "    \n",
    "    m.pred_path:\n",
    "        Path to the .npz file containing predictions\n",
    "    \n",
    "    m.X_train, m.X_test, m.y_train, m.y_test:\n",
    "        Assigned using m.get_Xy()\n",
    "    \n",
    "    m.test_stations, m.train_stations:\n",
    "        Dataframe containing station numbers and dates assigned using m.get_Xy()\n",
    "                                       \n",
    "    m.train_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 model_name,\n",
    "                 cluster_name = None,\n",
    "                 feature_combo = None,\n",
    "                 regressor=None,\n",
    "                 model_params=None,\n",
    "                 fit_params=None,\n",
    "                 save_path = '',\n",
    "                 data_path = r\"C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\processed_data\",\n",
    "                 target = 'ET0',\n",
    "                 score_fun_dict = {\n",
    "                       'MAE': sklearn.metrics.mean_absolute_error,\n",
    "                       'RMSE': lambda x, y: np.sqrt(sklearn.metrics.mean_squared_error(x, y)),\n",
    "                       'R2': sklearn.metrics.r2_score,\n",
    "                       'WI': wilmott_index\n",
    "                   }):\n",
    "        \n",
    "        \n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.save_path = save_path\n",
    "        self.model_path = os.path.join(save_path, self.model_name + '.joblib')\n",
    "        self.pred_path = os.path.join(save_path, self.model_name + '_pred.npz')\n",
    "        \n",
    "        self.score_fun_dict = score_fun_dict\n",
    "        \n",
    "        self.feature_combo = feature_combo\n",
    "        \n",
    "        self.cluster_name = cluster_name\n",
    "        \n",
    "        self.regressor = regressor\n",
    "        \n",
    "        self.model_params = model_params\n",
    "        \n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "        \n",
    "        # Using local paths, Github requires openning a session and entering user/pass\n",
    "        train_file_name = 'train.csv'\n",
    "        test_file_name = 'test.csv'\n",
    "        \n",
    "        if cluster_name is not None:\n",
    "            # Data is expected to be in a folder named by the cluster name\n",
    "            data_path = os.path.join(data_path, cluster_name)\n",
    "            \n",
    "            train_file_name = cluster_name + '_' + train_file_name\n",
    "            test_file_name = cluster_name + '_' + test_file_name\n",
    "            \n",
    "        self.train_path = os.path.join(data_path , train_file_name)\n",
    "        self.test_path = os.path.join(data_path , test_file_name)\n",
    "        \n",
    "        # Target variable\n",
    "        self.target = target\n",
    "        \n",
    "        # Load model if saved and print a message if not found\n",
    "        if self.load_model_() == True:\n",
    "            print('{} model loaded from {}'.format(model_name, save_path))\n",
    "            return\n",
    "        \n",
    "        # Else if the model is not saved\n",
    "        self.features, self.feature_names = self.get_features(feature_combo)\n",
    "        \n",
    "        print('Model not found at {}'.format(self.model_path))\n",
    "        print('MyModel object created without model')\n",
    "        \n",
    "        \n",
    "          \n",
    "    def get_features(self, feature_combo):\n",
    "        '''\n",
    "        Get full features from the JSON feature dictionary based on the combination number\n",
    "        '''\n",
    "        \n",
    "        feature_dict =  {'latitude': 'Latitude',\n",
    "                         'longitude': 'Longitude',\n",
    "                         'elevation': 'Elevation',\n",
    "                         'max_temp': 'Maximum temperature',\n",
    "                         'min_temp': 'Minimum temperature',\n",
    "                         'avg_temp': 'Average Temperature',\n",
    "                         'avg_ws': 'Average wind speed',\n",
    "                         'max_hum': 'Maximum humidity',\n",
    "                         'min_hum': 'Minimum humidity',\n",
    "                         'avg_hum': 'Average humidity',\n",
    "                         'Rs': 'Solar radiation',\n",
    "                         'inc_rad': 'Solar radiation',\n",
    "                         'Ra': 'Extraterrestrial radiation',\n",
    "                         'Rn': 'Net radiation',\n",
    "                         'ET0': 'Reference evapotranspiration',\n",
    "                         'month': 'Month'}\n",
    "        \n",
    "        # Getting features from the feature combos dictionary\n",
    "        path_to_feature_combos_dict = r\"C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\part_3\"\n",
    "        file_path = os.path.join(path_to_feature_combos_dict, 'feature_combos.json')\n",
    "        \n",
    "        assert os.path.isfile(file_path) == True,\\\n",
    "        'feature_combos dictionary not found at {}'.format(path_to_feature_combos_dict)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            feature_combos = json.load(file)\n",
    "        \n",
    "        feature_combo = str(feature_combo)\n",
    "        \n",
    "        assert feature_combo in feature_combos.keys(),\\\n",
    "        'Feature combination {} is not defined in the feature_combos dictionary'.format(feature_combo)\n",
    "        \n",
    "        features = feature_combos[feature_combo]\n",
    "        \n",
    "        feature_names = []\n",
    "        for feature in features:\n",
    "            feature_names.append(feature_dict[feature])\n",
    "        \n",
    "        return features, feature_names\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_train_test(self, how = 'selected_features'):\n",
    "        \"\"\"\n",
    "        Get training dataset from the defined data_path.\n",
    "        Returns the tuple (train, test)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        how:\n",
    "            'all' return all training dataset with all features\n",
    "            'selected_features' return training dataset with selected features only\n",
    "             \n",
    "        \"\"\"\n",
    "        train = pd.read_csv(self.train_path, parse_dates = [1])\n",
    "        test = pd.read_csv(self.test_path, parse_dates = [1])\n",
    "        \n",
    "        if how == 'all':\n",
    "            return (train, test)\n",
    "        \n",
    "        elif how == 'selected_features':\n",
    "            cols = ['st_num', 'date'] + self.features + [self.target]\n",
    "            return (train[cols], test[cols])\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_Xy(self):\n",
    "        \"\"\"\n",
    "        Returns (X_train, X_test, y_train, y_test)\n",
    "        Assigns them to attributes\n",
    "        Assigns dataframes of train/test stations with dates to attributes\n",
    "        (m.train_stations, m.test_stations)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loading train and test datasets\n",
    "        train, test = self.get_train_test(how = 'selected_features')\n",
    "        \n",
    "        X_train = train[self.features].to_numpy()\n",
    "        X_test = test[self.features].to_numpy()\n",
    "\n",
    "        # Checking if X has 1 dimension only\n",
    "        if len(self.features) < 2:\n",
    "            X_train = X_train.reshape(-1, 1)\n",
    "            X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "        y_train = train[self.target].to_numpy()\n",
    "        y_test = test[self.target].to_numpy()\n",
    "        \n",
    "        if not hasattr(self, 'X_train'):\n",
    "            self.X_train = X_train\n",
    "            self.X_test = X_test\n",
    "            self.y_train = y_train\n",
    "            self.y_test = y_test\n",
    "        \n",
    "        # Saving station numbers\n",
    "        self.test_stations = test[['st_num', 'date']]\n",
    "        self.train_stations = train[['st_num', 'date']]\n",
    "\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_model_(self, model, train_time):\n",
    "        '''\n",
    "        Assign model to attribute m.model\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.train_time = train_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_model(self, print_vals=True):\n",
    "        '''\n",
    "        Initialize the regressor and fit it to training data using the defined model_params and fit_params\n",
    "        \n",
    "        Paarameters:\n",
    "        ------------\n",
    "        \n",
    "        print_vals: Bool\n",
    "            Whether to print the model scores or not\n",
    "            \n",
    "        '''\n",
    "        X_train, X_test, y_train, y_test = self.get_Xy()\n",
    "        \n",
    "        model = self.regressor(**self.model_params)\n",
    "        \n",
    "        model.fit(X_train, y_train, **self.fit_params)\n",
    "        \n",
    "        self.add_model_(model, model.train_time)\n",
    "        \n",
    "        self.get_scores(predict=True, print_vals=print_vals)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def load_model_(self):\n",
    "        '''\n",
    "        Load model and predictions from the defined model_path and assign it to attribute m.model\n",
    "        and returns True.\n",
    "        If the model is not available at the defined path, returns False.\n",
    "        '''\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.model = load(self.model_path)\n",
    "            preds = np.load(self.pred_path)\n",
    "        \n",
    "            for pred in ['y_hat_train', 'y_hat_test', 'feature_combo']:\n",
    "                setattr (self, pred, preds[pred])\n",
    "                \n",
    "            # Feature combo was saved as an array\n",
    "            self.feature_combo = self.feature_combo[0]\n",
    "            \n",
    "            # Getting the list of features to be used\n",
    "            self.features, self.feature_names = self.get_features(self.feature_combo)\n",
    "            \n",
    "            # Adding X_train, y_train, X_test, y_test, train_stations, test_stations attributes\n",
    "            _ = self.get_Xy()\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_scores(self,\n",
    "                   print_vals = True,\n",
    "                   predict = False):\n",
    "        \n",
    "        '''\n",
    "        Predict y_train and y_test then compute evaluation metrics.\n",
    "        Predictions and metrics are assigned to attributes:\n",
    "        \n",
    "        self.y_hat_train: Training set predictions\n",
    "        self.y_hat_test: Test set predictions\n",
    "        \n",
    "        self.train_scores: Dictionary of training eval. metrics\n",
    "        self.test_scores: Dictionary of test eval. metrics\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        print_vals: Print evaluation metrics if True\n",
    "        \n",
    "        predict: Predict from data if True\n",
    "                 Use saved predictions if False\n",
    "        '''\n",
    "        \n",
    "        # Getting train and test predictions\n",
    "        if predict is True:\n",
    "            self.y_hat_test = self.model.predict(self.X_test)\n",
    "            self.y_hat_train = self.model.predict(self.X_train)\n",
    "        else:\n",
    "            assert (hasattr(self, 'y_hat_train') and hasattr(self, 'y_hat_test')),\\\n",
    "            'Load predictions or set predict = True to predict target variable' \n",
    "        \n",
    "        train_scores = {}\n",
    "        test_scores = {}\n",
    "        \n",
    "        for metric, fun in self.score_fun_dict.items():\n",
    "            train_scores[metric] = fun(self.y_train, self.y_hat_train)\n",
    "            test_scores[metric] = fun(self.y_test, self.y_hat_test)\n",
    "        \n",
    "\n",
    "        # Printing scores\n",
    "        if print_vals is True:\n",
    "            print('Train scores:')\n",
    "            for metric, val in train_scores.items():\n",
    "                print('{} = {:.3f}'.format(metric, val))\n",
    "            \n",
    "            print('\\n')\n",
    "            print('Test scores:')\n",
    "            for metric, val in test_scores.items():\n",
    "                print('{} = {:.3f}'.format(metric, val))\n",
    "                \n",
    "        self.train_scores = train_scores\n",
    "        self.test_scores = test_scores\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_station_scores(self):\n",
    "        '''\n",
    "        Get scores for every station to compare the performance of the model in different stations.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_stations = np.concatenate([self.test_stations['st_num'].unique(),\n",
    "                                       self.train_stations['st_num'].unique()])\n",
    "        \n",
    "        \n",
    "        df = {\n",
    "            'st_num': all_stations,\n",
    "            'dataset': []\n",
    "        }\n",
    "        \n",
    "        # Creating a dictionary of score_metric: empty list\n",
    "        scores = {key: [] for key in self.score_fun_dict.keys()}\n",
    "        df.update(scores)\n",
    "        \n",
    "        for st in all_stations:\n",
    "            if st in self.test_stations['st_num'].unique():\n",
    "                cond = self.test_stations['st_num'] == st\n",
    "                # Extracting index of the station \"st\"\n",
    "                idx = self.test_stations[cond].index\n",
    "                y = self.y_test[idx]\n",
    "                y_hat = self.y_hat_test[idx]\n",
    "                df['dataset'].append('test')\n",
    "            else:\n",
    "                cond = self.train_stations['st_num'] == st\n",
    "                # Extracting index of the station \"st\"\n",
    "                idx = self.train_stations[cond].index\n",
    "                y = self.y_train[idx]\n",
    "                y_hat = self.y_hat_train[idx]\n",
    "                df['dataset'].append('train')\n",
    "            \n",
    "            \n",
    "            # Computing score metric values\n",
    "            for metric, fun in self.score_fun_dict.items():\n",
    "                df[metric].append(fun(y, y_hat))\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        \n",
    "        # Adding algorithm name and model name\n",
    "        df.insert(0, 'name', self.model_name)\n",
    "        df.insert(0, 'feature_combo', self.feature_combo)\n",
    "        df.insert(0, 'algorithm', self.model.algorithm)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_map(self,\n",
    "                 path_to_st_def = r\"C:\\Users\\HP\\Desktop\\Git\\evapotranspiration\\processed_data\\station_definitions.csv\",\n",
    "                 marker_radius = 3,\n",
    "                 error_metric = 'RMSE',\n",
    "                 colors = ['black', 'blue'],\n",
    "                 location = [37.5, 28.5],\n",
    "                 zoom = 8):\n",
    "        '''\n",
    "        Plot stations in data with pop-ups for st_num and scores.\n",
    "        \n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        path_to_st_def: str\n",
    "            Path to the file containing station definitions (station_definitions.csv)\n",
    "        \n",
    "        marker_radius: int\n",
    "            Radius of the folium marker.\n",
    "        \n",
    "        error_metric: str ('RMSE' or 'MAE')\n",
    "            Error metric to use for scaling marker sizes. Larger markers have larger errors.\n",
    "            If None, all markers will have the same size.\n",
    "        \n",
    "        colors: list\n",
    "            List of color names to define the color of markers.\n",
    "            First color is for training stations and second is for test stations.\n",
    "        \n",
    "        location: list\n",
    "            Location of the center of the map to pass to folium.Map()\n",
    "        \n",
    "        zoom: int\n",
    "            Initial zoom of map to pass to folium.Map()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        tiles = 'https://stamen-tiles-{s}.a.ssl.fastly.net/terrain-background/{z}/{x}/{y}{r}.png'\n",
    "        attr = 'Map tiles by <a href=\"http://stamen.com\">Stamen Design</a>, <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a> &mdash; Map data &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors'\n",
    "\n",
    "        # Loading station definitions\n",
    "        st_def = pd.read_csv(path_to_st_def)[['st_num', 'latitude', 'longitude']]\n",
    "        \n",
    "        # Merging station definitions with station scores\n",
    "        df = self.get_station_scores()\n",
    "        df = df.merge(st_def, on = 'st_num')\n",
    "        \n",
    "        \n",
    "        m = folium.Map(location = location, zoom_start = zoom, tiles = tiles, attr = attr)\n",
    "\n",
    "\n",
    "        df['color'] = df['dataset'].replace({'train': colors[0], 'test': colors[1]})\n",
    "        \n",
    "        if error_metric is not None:\n",
    "            # Normalizing errors\n",
    "            max_error = df[error_metric].max()\n",
    "            min_error = df[error_metric].min()\n",
    "            df['radius'] = 0.5 + 1.5*(df[error_metric] - min_error)/(max_error - min_error)\n",
    "            \n",
    "            df['radius'] = df['radius'] * marker_radius\n",
    "        else:\n",
    "            df['radius'] = marker_radius\n",
    "            \n",
    "        for row in df.iterrows():\n",
    "            row = row[1]\n",
    "            \n",
    "            # Location of station\n",
    "            loc = [row['latitude'], row['longitude']]\n",
    "            \n",
    "            # Text in pop-up\n",
    "            txt = ''\n",
    "            txt += '<h5><b>Station: {}\\n</h5></b>'.format(row['st_num'])\n",
    "            for metric in ['MAE', 'RMSE', 'R2', 'WI']:\n",
    "                txt += '{}: {:.3f}<br>'.format(metric, row[metric])\n",
    "                \n",
    "            popup = folium.Popup(txt, min_width = 100, max_width = 100)\n",
    "            folium.CircleMarker(location = loc,\n",
    "                                fill = True,\n",
    "                                fill_opacity = 0.8,\n",
    "                                opacity = 1,\n",
    "                                color = row['color'],\n",
    "                                radius = row['radius']\n",
    "                                ).add_child(popup).add_to(m)\n",
    "\n",
    "        display(m)\n",
    "        \n",
    "        return m\n",
    "\n",
    "  \n",
    "        \n",
    "    \n",
    "    def plot_predictions(self, title, alpha = 0.8, show_scores = True, dpi = 70):\n",
    "    \n",
    "        \"\"\"\n",
    "        Plot real values vs. predictions.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "\n",
    "        alpha: Opacity of scatter plot points\n",
    "\n",
    "        show_scores: Writes model properties and evaluation metrics on the right\n",
    "                     side of the graph\n",
    "        \"\"\"\n",
    "        # Predicting\n",
    "        assert hasattr(self, 'model'), 'Model not loaded, add or load model first'\n",
    "        \n",
    "        if not hasattr(self, 'train_scores') or not hasattr(self, 'test_scores'):\n",
    "            self.get_scores(print_vals = False)\n",
    "        \n",
    "\n",
    "        if show_scores is True:\n",
    "            fig, axs = plt.subplots(1, 2, figsize = (12, 8),\n",
    "                                    gridspec_kw={'width_ratios': [3, 1]}, dpi = dpi, tight_layout = True)\n",
    "            ax = axs[0]\n",
    "            ax1 = axs[1]\n",
    "            \n",
    "            eval_list_train = []\n",
    "            for metric, val in self.train_scores.items():\n",
    "                eval_list_train.append('{}:  {:.3f}'.format(metric, val))\n",
    "            \n",
    "            eval_list_test = []\n",
    "            for metric, val in self.test_scores.items():\n",
    "                eval_list_test.append('{}:  {:.3f}'.format(metric, val))\n",
    "\n",
    "            # Inserting texts to plot\n",
    "            x_start = 0.05\n",
    "            y_start = 1\n",
    "\n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Model:', [self.model_name])\n",
    "\n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Features:', self.feature_names)\n",
    "\n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Train:', eval_list_train)\n",
    "            \n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Test:', eval_list_test)\n",
    "\n",
    "            # Turning axis off\n",
    "            ax1.axis('off')\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize = (8, 8), dpi = dpi, tight_layout = True)\n",
    "\n",
    "\n",
    "        # Setting Title\n",
    "        ax.set_title(title, fontsize = 14)\n",
    "\n",
    "        # Plotting true to prediction points\n",
    "        ax.plot(self.y_test, self.y_hat_test, 'x', color = 'blue', alpha = alpha)\n",
    "\n",
    "        # Plotting reference line\n",
    "        ref_line = [min(self.y_test.min(), self.y_hat_test.min()) * 0.9,\n",
    "                    max(self.y_test.max(), self.y_hat_test.max()) * 1.03]\n",
    "        \n",
    "        ax.plot(ref_line, ref_line, '--', color = 'black', linewidth = 3)\n",
    "\n",
    "        ax.set_xlabel('Measured Values', fontsize = 12)\n",
    "        ax.set_ylabel('Predicted Values', fontsize = 12)\n",
    "        ax.axis('equal')\n",
    "\n",
    "        return ax\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_station_series(self, st_num = None, which = 'test', show_scores = True, dpi = 70):\n",
    "        \n",
    "        '''\n",
    "        Plot a time series of a certain station.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        st_num: int\n",
    "            The number of the station to plot. If None, a random station is plotted.\n",
    "            \n",
    "        which: str 'test' or 'train'\n",
    "            The dataset from which the station is chosen, train or test.\n",
    "        \n",
    "        show_scores: bool\n",
    "            Determines whether to display the scores of the plotted station or not.\n",
    "        '''\n",
    "        # Getting a series of all stations and a list of unique stations\n",
    "        # based on 'which' parameter (test or train)\n",
    "        if which == 'test':\n",
    "            station_df = self.test_stations\n",
    "            y_measured = self.y_test\n",
    "            y_hat = self.y_hat_test\n",
    "        else:\n",
    "            station_df = self.train_stations.sort_values(by = ['st_num', 'date'])\n",
    "            \n",
    "            # Resorting training data (Previously shuffled for cross-validation)\n",
    "            idx = station_df.index\n",
    "            y_measured = self.y_train[idx]\n",
    "            y_hat = self.y_hat_train[idx]\n",
    "\n",
    "        stations_available = station_df['st_num'].unique()\n",
    "        \n",
    "        # Get a random station if station number is not defined\n",
    "        if st_num is None:\n",
    "            st_to_plot = np.random.choice(stations_available)\n",
    "        \n",
    "        else:\n",
    "            assert st_num in stations_available, 'Station {} not found in {} stations'.format(st_num, which) \n",
    "            st_to_plot = st_num\n",
    "\n",
    "        cond = station_df['st_num'] == st_to_plot\n",
    "        idx = station_df[cond].index\n",
    "        \n",
    "        x = station_df.loc[idx, 'date'].to_list()\n",
    "\n",
    "        y_measured = y_measured[idx]\n",
    "        y_hat = y_hat[idx]\n",
    "\n",
    "        if show_scores == True:\n",
    "            fig, axs = plt.subplots(1, 2,\n",
    "                                   figsize = (21, 6),\n",
    "                                   gridspec_kw={'width_ratios': [5, 1]},\n",
    "                                   tight_layout = True,\n",
    "                                   dpi = dpi)\n",
    "\n",
    "            ax = axs[0]\n",
    "            \n",
    "            ax1 = axs[1]\n",
    "            \n",
    "            # Inserting scores to plot\n",
    "            station_scores = self.get_station_scores()\n",
    "            \n",
    "            cond = station_scores['st_num'] == st_to_plot\n",
    "            station_score = station_scores[cond]\n",
    "            \n",
    "            eval_list = []\n",
    "            for metric in ['MAE', 'RMSE', 'R2', 'WI']:\n",
    "                val = station_score[metric].to_numpy()[0]\n",
    "                eval_list.append('{}:  {:.3f}'.format(metric, val))\n",
    "            \n",
    "            x_start = 0.05\n",
    "            y_start = 1\n",
    "\n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Dataset:', station_score['dataset'].to_numpy())\n",
    "\n",
    "            x_start, y_start = text_block(ax1, x_start, y_start, 'Scores:', eval_list)\n",
    "            \n",
    "            # Turning axis off\n",
    "            ax1.axis('off')\n",
    "            \n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize = (16, 5),\n",
    "                                   tight_layout = True,\n",
    "                                   dpi = dpi)\n",
    "            \n",
    "        ax.set_title('ET0 Measurements vs Predictions / Station: {}'.format(st_to_plot))\n",
    "            \n",
    "        ax.plot(x, y_measured, 'green', label = 'Measured ET0', linestyle = '--', linewidth = 2.5)\n",
    "        ax.plot(x, y_hat, 'skyblue', label = 'Predicted ET0')\n",
    "        \n",
    "        ax.set_xlabel('Dates')\n",
    "        ax.set_ylabel('ET0 (mm/day)')\n",
    "        ax.legend()\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save_params_(self,\n",
    "                     file_name = 'params.csv'\n",
    "                   ):\n",
    "        '''\n",
    "        Save the parameters of the model to a CSV file.\n",
    "        The method checks if the defined file_name is available in the defined directory,\n",
    "        and appends the parameters to that file. Else, a new file is created.\n",
    "        \n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        file_name: str\n",
    "        '''\n",
    "        \n",
    "        file_path = os.path.join(self.save_path, file_name)\n",
    "        \n",
    "        # Getting the parameter values from the model object\n",
    "        param_dict = self.model.get_params()\n",
    "        \n",
    "        # Creating a dictionary of the new entries\n",
    "        new_dict = {}\n",
    "\n",
    "        new_dict['algorithm'] = self.model.algorithm\n",
    "        new_dict['feature_combo'] = self.feature_combo\n",
    "        new_dict['name'] = self.model_name\n",
    "        new_dict['train_time'] = self.model.train_time\n",
    "        new_dict.update(param_dict)\n",
    "        \n",
    "        # Checking if file is available\n",
    "        if os.path.isfile(file_path) is not True:\n",
    "            param_df = pd.DataFrame(new_dict, index = [0])\n",
    "        else:\n",
    "            param_df = pd.read_csv(file_path)\n",
    "            param_df = param_df.append(pd.DataFrame(new_dict, index = [0]), ignore_index = True)\n",
    "            param_df = param_df.drop_duplicates(subset = ['algorithm', 'feature_combo', 'name'],\n",
    "                                                keep = 'last')\n",
    "        \n",
    "        param_df.to_csv(file_path, index = False)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def save_scores_(self,\n",
    "                     scores_file_name = 'scores.csv',\n",
    "                     station_scores_file_name = 'station_scores.csv'\n",
    "                   ):\n",
    "        \n",
    "        '''\n",
    "        Save model evaluation metrics to a CSV file. If the file exists values are appended to it\n",
    "        and duplicates are dropped. Scores (evaluation metrics) per station are saved to the file defined in\n",
    "        station_scores_file_name.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "            \n",
    "        scores_file_name: str\n",
    "            Name of the file including total scores\n",
    "            \n",
    "        station_scores_file_name: str\n",
    "            Name of the file including scores per station\n",
    "\n",
    "        '''\n",
    "        file_path = os.path.join(self.save_path, scores_file_name)\n",
    "        \n",
    "        train_dict = {\n",
    "            'algorithm': self.model.algorithm,\n",
    "            'feature_combo': self.feature_combo,\n",
    "            'name': self.model_name,\n",
    "            'train_test': 'train'\n",
    "        }\n",
    "        \n",
    "        train_dict.update(self.train_scores)\n",
    "        \n",
    "        test_dict = {\n",
    "            'algorithm': self.model.algorithm,\n",
    "            'feature_combo': self.feature_combo,\n",
    "            'name': self.model_name,\n",
    "            'train_test': 'test'\n",
    "        }\n",
    "        \n",
    "        test_dict.update(self.test_scores)\n",
    "        \n",
    "        # Checking if file is available\n",
    "        if os.path.isfile(file_path) is not True:\n",
    "            score_df = pd.DataFrame([train_dict, test_dict])\n",
    "        else:\n",
    "            score_df = pd.read_csv(file_path)\n",
    "            score_df = score_df.append(pd.DataFrame([train_dict, test_dict]), ignore_index = True)\n",
    "            score_df = score_df.drop_duplicates(subset = ['algorithm', 'feature_combo', 'name', 'train_test'],\n",
    "                                                keep = 'last')\n",
    "        \n",
    "        score_df.to_csv(file_path, index = False)\n",
    "        \n",
    "        # Saving station scores\n",
    "        station_scores = self.get_station_scores()\n",
    "        \n",
    "        file_path = os.path.join(self.save_path, station_scores_file_name)\n",
    "        \n",
    "        # Checking if file is available\n",
    "        if os.path.isfile(file_path) is not True:\n",
    "            station_scores.to_csv(file_path, index = False)\n",
    "\n",
    "        else:\n",
    "            old_station_scores = pd.read_csv(file_path)\n",
    "            df = old_station_scores.append(station_scores, ignore_index = True)\n",
    "            df = df.drop_duplicates(subset = ['algorithm', 'feature_combo', 'name', 'st_num'], keep = 'last')\n",
    "            df.to_csv(file_path, index = False)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def save_model_(self):\n",
    "        '''\n",
    "        Save model and predictions to the defined model_path\n",
    "        '''\n",
    "        # Saving model\n",
    "        dump(self.model, self.model_path)\n",
    "        \n",
    "        # Saving predictions\n",
    "        assert (hasattr(self, 'y_hat_train') and hasattr(self, 'y_hat_test')),\\\n",
    "            'Predictions not available, only model was saved'\n",
    "        \n",
    "        preds = ['y_hat_train', 'y_hat_test']\n",
    "        preds = dict([(p, getattr(self, p)) for p in preds])\n",
    "        # Adding feature combination number\n",
    "        preds['feature_combo'] = [self.feature_combo]\n",
    "        np.savez(self.pred_path, **preds)\n",
    "        \n",
    "            \n",
    "    def save(self):\n",
    "        '''\n",
    "        Save model, model predictions, model scores, model parameters, and station scores\n",
    "        to the defined save path.\n",
    "        '''\n",
    "        \n",
    "        self.save_scores_()\n",
    "        self.save_model_()\n",
    "        self.save_params_()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUK Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puk(x1, x2, sigma, omega):\n",
    "    '''\n",
    "    Pearson VII Universal Kernel function\n",
    "    Based on: https://github.com/rlphilli/sklearn-PUK-kernel/blob/master/PUK_kernel.py\n",
    "    '''\n",
    "    \n",
    "    dis = cdist(x1, x2, 'sqeuclidean')\n",
    "    \n",
    "    kernel = (1 + 4 * dis * (2**(1.0/omega) - 1) / sigma**2)**omega\n",
    "    \n",
    "    return 1 / kernel\n",
    "\n",
    "\n",
    "class PUK(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, sigma = 1, omega = 10):\n",
    "        super(PUK,self).__init__()\n",
    "        self.sigma = sigma\n",
    "        self.omega = omega\n",
    "\n",
    "    def transform(self, X):\n",
    "        return puk(X, self.X_train_, sigma = self.sigma, omega = self.omega)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_train_ = X\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
